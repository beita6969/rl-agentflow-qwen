#!/usr/bin/env python3
"""
æ¨ç†è„šæœ¬ - æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹
"""
import sys
import os
import asyncio
import argparse

sys.path.insert(0, 'src')

from rl_workflow_generator import RLWorkflowGenerator
from aflow_executor import AFlowExecutor
from reward_computer import RewardComputer


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ¨ç†æµ‹è¯•")
    parser.add_argument('--checkpoint', type=str, required=True, help='LoRAæ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--problem', type=str, required=True, help='é—®é¢˜æ–‡æœ¬')
    parser.add_argument('--problem-type', type=str, default='math', choices=['math', 'code', 'qa'], help='é—®é¢˜ç±»å‹')
    parser.add_argument('--ground-truth', type=str, default=None, help='æ­£ç¡®ç­”æ¡ˆï¼ˆå¯é€‰ï¼‰')
    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ” æ¨ç†æµ‹è¯•")
    print("=" * 60)

    # 1. åŠ è½½RLæ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹: {args.checkpoint}")
    generator = RLWorkflowGenerator(
        base_model="Qwen/Qwen2.5-7B-Instruct",
        lora_checkpoint=args.checkpoint,
        device_ids=[2, 3]
    )

    # 2. ç”Ÿæˆå·¥ä½œæµ
    print(f"\nğŸ“ é—®é¢˜: {args.problem}")
    print(f"   ç±»å‹: {args.problem_type}")

    result = generator.generate_workflow(
        problem=args.problem,
        problem_type=args.problem_type,
        temperature=0.7
    )

    print(f"\nâœ… å·¥ä½œæµç”Ÿæˆ:")
    print(f"   æœ‰æ•ˆæ€§: {result['valid']}")
    if result['error']:
        print(f"   é”™è¯¯: {result['error']}")

    print(f"\nğŸ“„ ç”Ÿæˆçš„å·¥ä½œæµä»£ç :")
    print(result['workflow_code'])

    # 3. æ‰§è¡Œå·¥ä½œæµ
    print(f"\nâš™ï¸  æ‰§è¡Œå·¥ä½œæµ...")
    executor = AFlowExecutor(
        llm_config_path="config/aflow_llm.yaml",
        llm_model_name="gpt-4o-mini"
    )

    answer, cost, metadata = await executor.execute_workflow(
        workflow_code=result['workflow_code'],
        problem=args.problem,
        problem_type=args.problem_type
    )

    print(f"\nâœ… æ‰§è¡Œç»“æœ:")
    print(f"   æˆåŠŸ: {metadata['success']}")
    print(f"   ç­”æ¡ˆ: {answer}")
    print(f"   æˆæœ¬: ${cost:.6f}")
    print(f"   æ—¶é—´: {metadata.get('execution_time', 0):.2f}ç§’")

    # 4. è®¡ç®—å¥–åŠ±ï¼ˆå¦‚æœæä¾›äº†ground truthï¼‰
    if args.ground_truth:
        print(f"\nğŸ¯ è¯„ä¼°:")
        print(f"   æ­£ç¡®ç­”æ¡ˆ: {args.ground_truth}")

        reward_computer = RewardComputer()
        reward = reward_computer.compute_reward(
            problem=args.problem,
            prediction=answer,
            ground_truth=args.ground_truth,
            problem_type=args.problem_type,
            metadata=metadata
        )

        print(f"   å¥–åŠ±åˆ†æ•°: {reward:.2f}")

    print("\n" + "=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
