# AFlow æ·±å…¥ç ”ç©¶æˆæœ

**ç ”ç©¶æ—¶é—´**: 2025-11-16
**ç ”ç©¶æ–‡ä»¶æ•°**: 38+ Python æ–‡ä»¶
**ç ”ç©¶ä»“åº“**: `/home/yijia/.claude/11/AFlow`

---

## ğŸ¯ æ ¸å¿ƒå‘ç°

### å‘ç° 1: LLM é…ç½®çš„æ­£ç¡®æµç¨‹

**é—®é¢˜æ ¹æº**: `'dict' object has no attribute 'call_with_format'`

**æ­£ç¡®çš„æ•°æ®æµ**:
```
YAML â†’ dict â†’ LLMsConfig(dict) â†’ LLMsConfig.get(name) â†’ LLMConfig å®ä¾‹ â†’
create_llm_instance(LLMConfig) â†’ AsyncLLM å®ä¾‹ â†’ operator.Custom(AsyncLLM) â†’
AsyncLLM.call_with_format() âœ“
```

**å…³é”®ä»£ç **:
```python
# 1. LLMsConfig.get() è¿”å› LLMConfig å®ä¾‹ï¼ˆä¸æ˜¯ dictï¼ï¼‰
llm_config = LLMsConfig(models_dict).get("gpt-4o-mini")
# è¿”å›ç±»å‹: LLMConfig å®ä¾‹

# 2. create_llm_instance() æ”¯æŒä¸‰ç§è¾“å…¥
def create_llm_instance(llm_config):
    if isinstance(llm_config, LLMConfig):  # æ¨è
        return AsyncLLM(llm_config)
    elif isinstance(llm_config, str):      # ä¹Ÿæ”¯æŒ
        return AsyncLLM(llm_config)
    elif isinstance(llm_config, dict):     # ä¼šè½¬æ¢
        return AsyncLLM(LLMConfig(llm_config))
```

**ä¿®å¤æ–¹æ¡ˆ**: åœ¨ `_get_llm_config()` ä¸­æ·»åŠ ç±»å‹æ£€æŸ¥å’Œè½¬æ¢ã€‚

---

### å‘ç° 2: AnswerGenerate ä¸æ¥å— instruction å‚æ•°ï¼

**é”™è¯¯**: `TypeError: AnswerGenerate.__call__() got an unexpected keyword argument 'instruction'`

**ç®—å­ API ç­¾åæ±‡æ€»**:

| ç®—å­ | å‚æ•° | è¿”å›å€¼ |
|------|------|--------|
| `Custom` | `input: str`<br>`instruction: str` | `{'response': str}` |
| `AnswerGenerate` | `input: str` **ï¼ˆåªæœ‰è¿™ä¸€ä¸ªï¼ï¼‰** | `{'thought': str, 'answer': str}` |
| `Programmer` | `problem: str`<br>`analysis: str = "None"` | `{'code': str, 'output': str}` |
| `ScEnsemble` | `solutions: List[str]`<br>`problem: str` | `{'response': str}` |
| `Review` | `problem: str`<br>`solution: str` | `{'review_result': bool, 'feedback': str}` |
| `Revise` | `problem: str`<br>`solution: str`<br>`feedback: str` | `{'solution': str}` |

**æ­£ç¡®ç”¨æ³•**:
```python
# âŒ é”™è¯¯
result = await self.answer_generate(input=problem, instruction="...")

# âœ… æ­£ç¡®
result = await self.answer_generate(input=problem)
thought = result['thought']
answer = result['answer']
```

**å¦‚æœéœ€è¦è‡ªå®šä¹‰æŒ‡ä»¤ï¼Œåº”è¯¥ä½¿ç”¨ Custom ç®—å­**:
```python
result = await self.custom(input=problem, instruction="Solve step by step")
answer = result['response']
```

---

### å‘ç° 3: Workflow æ ‡å‡†æ¨¡æ¿

**æ‰€æœ‰ Workflow éƒ½éµå¾ªç›¸åŒç»“æ„**:

```python
import workspace.{problem_type}.workflows.template.operator as operator
from scripts.async_llm import create_llm_instance
from scripts.evaluator import DatasetType

class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        # å…³é”®ï¼šä½¿ç”¨ create_llm_instance
        self.llm = create_llm_instance(llm_config)
        # åˆå§‹åŒ–ç®—å­ï¼ˆä¼ å…¥ AsyncLLM å®ä¾‹ï¼‰
        self.custom = operator.Custom(self.llm)

    async def __call__(self, problem: str):
        """æ‰§è¡Œå·¥ä½œæµ"""
        solution = await self.custom(input=problem, instruction="")
        # å…³é”®ï¼šå¿…é¡»è¿”å› (answer, cost) å…ƒç»„
        return solution['response'], self.llm.get_usage_summary()["total_cost"]
```

**å…³é”®ç‚¹**:
1. ä½¿ç”¨ `create_llm_instance(llm_config)` åˆ›å»º LLM
2. ç®—å­åˆå§‹åŒ–ä¼ å…¥ `self.llm`ï¼ˆAsyncLLM å®ä¾‹ï¼‰
3. ç®—å­è¿”å›å€¼æ˜¯å­—å…¸ï¼Œéœ€è¦è®¿é—®å¯¹åº”é”®ï¼ˆå¦‚ `['response']`ï¼‰
4. å¿…é¡»è¿”å› `(solution, cost)` å…ƒç»„
5. Cost é€šè¿‡ `self.llm.get_usage_summary()["total_cost"]` è·å–

---

## ğŸ”§ å…·ä½“ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤ 1: å½»åº•ä¿®å¤ LLM é…ç½®é”™è¯¯

**ä½ç½®**: `src/aflow_executor.py:251-265`

**é—®é¢˜**: `_get_llm_config()` å¯èƒ½è¿”å›é”™è¯¯ç±»å‹

**ä¿®å¤ä»£ç **:
```python
def _get_llm_config(self):
    """è·å–LLMé…ç½®ï¼ˆç¡®ä¿è¿”å›æ­£ç¡®ç±»å‹ï¼‰"""
    from scripts.async_llm import LLMsConfig, LLMConfig

    try:
        if self.llm_configs:
            result = self.llm_configs.get(self.llm_model_name)
        else:
            result = LLMsConfig.default().get(self.llm_model_name)

        # ç±»å‹éªŒè¯ï¼ˆå…³é”®ï¼ï¼‰
        if isinstance(result, LLMConfig):
            return result
        elif isinstance(result, dict):
            # å¦‚æœæ„å¤–è¿”å›äº† dictï¼Œè½¬æ¢ä¸º LLMConfig
            print(f"âš ï¸  è­¦å‘Šï¼šget() è¿”å›äº† dictï¼Œæ­£åœ¨è½¬æ¢ä¸º LLMConfig")
            return LLMConfig(result)
        elif isinstance(result, str):
            return result
        else:
            print(f"âš ï¸  æœªçŸ¥ç±»å‹: {type(result)}ï¼Œé™çº§ä¸ºå­—ç¬¦ä¸²")
            return self.llm_model_name

    except Exception as e:
        print(f"âš ï¸  è·å–LLMé…ç½®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return self.llm_model_name
```

---

### ä¿®å¤ 2: ä¼˜åŒ– Workflow ç”Ÿæˆ Prompt

**ä½ç½®**: `src/rl_workflow_generator.py:113-139`

**é—®é¢˜**: Prompt æ²¡æœ‰æ˜ç¡®è¯´æ˜æ¯ä¸ªç®—å­çš„ç²¾ç¡® API

**ä¿®å¤ä»£ç **:
```python
def _build_generation_prompt(self, problem: str, problem_type: str) -> str:
    """æ„å»ºæç¤ºè¯ï¼Œæ˜ç¡®ç®—å­ API"""

    prompt = f"""Generate a Python Workflow class. Follow the exact template and API signatures.

IMPORTANT: Only use operators listed below with their EXACT parameters.

Available Operators:

1. Custom(llm) - Most flexible
   Call: await self.custom(input=str, instruction=str)
   Returns: {{'response': str}}

2. AnswerGenerate(llm) - Step-by-step reasoning
   Call: await self.answer_generate(input=str)  â† NO instruction parameter!
   Returns: {{'thought': str, 'answer': str}}

3. Programmer(llm) - Auto-generate and execute code
   Call: await self.programmer(problem=str, analysis=str)
   Returns: {{'code': str, 'output': str}}

Template (fill in the logic):

import workspace.{problem_type}.workflows.template.operator as operator
from scripts.async_llm import create_llm_instance
from scripts.evaluator import DatasetType

class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        # Initialize operators (e.g., self.custom = operator.Custom(self.llm))

    async def __call__(self, problem: str):
        # Use operators to solve: {problem}
        # Must return (solution, cost) tuple
        # Example: return solution['response'], self.llm.get_usage_summary()["total_cost"]
        pass
"""
    return prompt
```

---

### ä¿®å¤ 3: æ·»åŠ ä»£ç éªŒè¯

**ä½ç½®**: `src/rl_workflow_generator.py:213-256`

**åœ¨ `_parse_workflow_code` ä¸­æ·»åŠ éªŒè¯**:

```python
def _parse_workflow_code(self, generated_text: str, problem_type: str):
    """è§£æå¹¶éªŒè¯å·¥ä½œæµä»£ç """

    # ... ç°æœ‰ä»£ç æå–é€»è¾‘ ...

    # æ–°å¢ï¼šéªŒè¯å¸¸è§é”™è¯¯
    if code:
        # æ£€æŸ¥ AnswerGenerate é”™è¯¯ç”¨æ³•
        if "answer_generate(" in code and "instruction=" in code:
            print(f"âš ï¸  æ£€æµ‹åˆ°é”™è¯¯ï¼šAnswerGenerate ä¸æ¥å— instruction å‚æ•°")
            # è‡ªåŠ¨ä¿®å¤
            code = code.replace(
                "await self.answer_generate(input=problem, instruction=",
                "await self.answer_generate(input=problem) # Fixed: removed instruction="
            )
            print(f"  å·²è‡ªåŠ¨ä¿®å¤")

        # æ£€æŸ¥æ˜¯å¦è¿”å›äº† cost
        if "return" in code and "get_usage_summary" not in code:
            print(f"âš ï¸  è­¦å‘Šï¼šå¯èƒ½ç¼ºå°‘ cost è®¡ç®—")

    # ... ç»§ç»­è¯­æ³•éªŒè¯ ...
```

---

## ğŸ“ æ¨èçš„å·¥ä½œæµæ¨¡å¼

### æ¨¡å¼ 1: ç®€å•å•æ­¥ï¼ˆæ¨èç”¨äºå¤§å¤šæ•°æƒ…å†µï¼‰

```python
class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.custom = operator.Custom(self.llm)

    async def __call__(self, problem: str):
        solution = await self.custom(
            input=problem,
            instruction="Solve this problem step by step and provide the final answer."
        )
        return solution['response'], self.llm.get_usage_summary()["total_cost"]
```

### æ¨¡å¼ 2: ä½¿ç”¨ Programmerï¼ˆæ•°å­¦é—®é¢˜è‡ªåŠ¨æ‰§è¡Œä»£ç ï¼‰

```python
class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.programmer = operator.Programmer(self.llm)

    async def __call__(self, problem: str):
        result = await self.programmer(problem=problem, analysis="None")
        return result['output'], self.llm.get_usage_summary()["total_cost"]
```

### æ¨¡å¼ 3: Self-Consistencyï¼ˆç”Ÿæˆå¤šä¸ªç­”æ¡ˆå¹¶é€‰æ‹©æœ€ä½³ï¼‰

```python
class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        self.custom = operator.Custom(self.llm)
        self.sc_ensemble = operator.ScEnsemble(self.llm)

    async def __call__(self, problem: str):
        # ç”Ÿæˆå¤šä¸ªå€™é€‰ç­”æ¡ˆ
        solutions = []
        for _ in range(3):
            sol = await self.custom(input=problem, instruction="")
            solutions.append(sol['response'])

        # é€‰æ‹©æœ€ä¸€è‡´çš„ç­”æ¡ˆ
        final = await self.sc_ensemble(solutions=solutions, problem=problem)
        return final['response'], self.llm.get_usage_summary()["total_cost"]
```

---

## ğŸ¯ ç«‹å³è¡ŒåŠ¨è®¡åˆ’

### ä¼˜å…ˆçº§ 1ï¼ˆç«‹å³ä¿®å¤ï¼‰

1. âœ… **æ›´æ–° `_get_llm_config()`** - æ·»åŠ ç±»å‹æ£€æŸ¥å’Œè½¬æ¢
2. âœ… **ä¼˜åŒ–ç”Ÿæˆ Prompt** - æ˜ç¡®ç®—å­ API ç­¾å
3. âœ… **æ·»åŠ ä»£ç éªŒè¯** - è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤å¸¸è§é”™è¯¯

### ä¼˜å…ˆçº§ 2ï¼ˆçŸ­æœŸä¼˜åŒ–ï¼‰

4. æ·»åŠ  Few-shot ç¤ºä¾‹åˆ° Prompt
5. å®ç°ä»£ç è‡ªåŠ¨ä¿®å¤æœºåˆ¶
6. ä¼˜åŒ– temperature å’Œé‡‡æ ·å‚æ•°

### ä¼˜å…ˆçº§ 3ï¼ˆé•¿æœŸæ”¹è¿›ï¼‰

7. å®ç°å¥–åŠ±ä¿¡å·ä¿®æ­£ï¼ˆæƒ©ç½šæ— æ•ˆç”Ÿæˆï¼‰
8. æ·»åŠ  Curriculum Learning
9. æ”¶é›†å’Œåˆ†ææˆåŠŸçš„ Workflow æ¨¡å¼

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **LLM é…ç½®**: `/home/yijia/.claude/11/AFlow/scripts/async_llm.py`
- **ç®—å­å®šä¹‰**: `/home/yijia/.claude/11/AFlow/scripts/operators.py`
- **å®˜æ–¹ç¤ºä¾‹**: `/home/yijia/.claude/11/AFlow/workspace/*/workflows/round_1/graph.py`
- **ç®—å­ JSON**: `/home/yijia/.claude/11/AFlow/workspace/*/workflows/template/operator.json`

---

**ç ”ç©¶å®Œæˆ** âœ…
