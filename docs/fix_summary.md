# ä¿®å¤æ€»ç»“æŠ¥å‘Š

**æ—¶é—´**: 2025-11-16
**çŠ¶æ€**: âœ… å…³é”®ä¿®å¤å·²å®Œæˆ

---

## ğŸ“Š ç ”ç©¶æˆæœ

é€šè¿‡æ·±å…¥ç ”ç©¶ AFlow ä»“åº“ï¼ˆ38+ Python æ–‡ä»¶ï¼‰ï¼Œå‘ç°äº†é—®é¢˜çš„æ ¹æœ¬åŸå› ï¼š

### é—®é¢˜ 1: LLM é…ç½®ç±»å‹é”™è¯¯
**æ ¹æœ¬åŸå› **: `LLMsConfig.get()` è¿”å› `LLMConfig` å®ä¾‹ï¼Œä½†ä»£ç æ²¡æœ‰éªŒè¯ç±»å‹ï¼Œå¯¼è‡´æŸäº›æƒ…å†µä¸‹ä¼ é€’äº†é”™è¯¯çš„å¯¹è±¡ã€‚

### é—®é¢˜ 2: AnswerGenerate API é”™è¯¯
**æ ¹æœ¬åŸå› **: `AnswerGenerate` åªæ¥å— `input` å‚æ•°ï¼Œä½† Prompt æ²¡æœ‰æ˜ç¡®è¯´æ˜ï¼Œå¯¼è‡´ Qwen é”™è¯¯åœ°æ·»åŠ äº† `instruction` å‚æ•°ã€‚

---

## âœ… å·²åº”ç”¨çš„ä¿®å¤

### ä¿®å¤ 1: `src/aflow_executor.py:251-281`

**å¢å¼ºäº† `_get_llm_config()` æ–¹æ³•**ï¼š

```python
def _get_llm_config(self):
    """è·å–LLMé…ç½®ï¼ˆç¡®ä¿è¿”å›æ­£ç¡®ç±»å‹ï¼‰"""
    from scripts.async_llm import LLMsConfig, LLMConfig

    try:
        if self.llm_configs:
            result = self.llm_configs.get(self.llm_model_name)
        else:
            result = LLMsConfig.default().get(self.llm_model_name)

        # âœ¨ æ–°å¢ï¼šç±»å‹éªŒè¯
        if isinstance(result, LLMConfig):
            return result
        elif isinstance(result, dict):
            print(f"âš ï¸  è­¦å‘Šï¼šget() è¿”å›äº† dictï¼Œæ­£åœ¨è½¬æ¢ä¸º LLMConfig")
            return LLMConfig(result)
        elif isinstance(result, str):
            return result
        else:
            print(f"âš ï¸  æœªçŸ¥ç±»å‹: {type(result)}ï¼Œé™çº§ä¸ºå­—ç¬¦ä¸²")
            return self.llm_model_name

    except Exception as e:
        print(f"âš ï¸  è·å–LLMé…ç½®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()  # âœ¨ æ–°å¢ï¼šå®Œæ•´é”™è¯¯å †æ ˆ
        return self.llm_model_name
```

**æ•ˆæœ**:
- âœ… è‡ªåŠ¨æ£€æµ‹å¹¶è½¬æ¢é”™è¯¯ç±»å‹
- âœ… å®Œæ•´çš„é”™è¯¯æ—¥å¿—
- âœ… å¤šå±‚é™çº§æœºåˆ¶

---

### ä¿®å¤ 2: `src/rl_workflow_generator.py:113-154`

**ä¼˜åŒ–äº†ç”Ÿæˆ Prompt**ï¼š

```python
def _build_generation_prompt(self, problem: str, problem_type: str) -> str:
    """æ„å»ºæç¤ºè¯ï¼Œæ˜ç¡®ç®—å­ API"""

    prompt = f"""Generate a Python Workflow class. Follow the exact template and API signatures.

CRITICAL: Only use operators listed below with their EXACT parameters!

Available Operators:

1. Custom(llm) - Most flexible, for any custom task
   Call: await self.custom(input=str, instruction=str)
   Returns: {{'response': str}}

2. AnswerGenerate(llm) - Step-by-step reasoning
   Call: await self.answer_generate(input=str)  â† NO instruction parameter!
   Returns: {{'thought': str, 'answer': str}}

3. Programmer(llm) - Auto-generate and execute Python code
   Call: await self.programmer(problem=str, analysis=str)
   Returns: {{'code': str, 'output': str}}

Template (complete the __call__ method):

import workspace.{problem_type}.workflows.template.operator as operator
from scripts.async_llm import create_llm_instance
from scripts.evaluator import DatasetType

class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        # Example: self.custom = operator.Custom(self.llm)

    async def __call__(self, problem: str):
        # Solve: {problem}
        # MUST return (solution, cost) tuple
        # Example: return solution['response'], self.llm.get_usage_summary()["total_cost"]
        pass
"""

    return prompt
```

**æ•ˆæœ**:
- âœ… æ˜ç¡®æ ‡æ³¨æ¯ä¸ªç®—å­çš„ç²¾ç¡® API
- âœ… ç‰¹åˆ«è­¦å‘Š AnswerGenerate ä¸æ¥å— instruction
- âœ… æä¾›å®Œæ•´çš„æ¨¡æ¿ç¤ºä¾‹
- âœ… å¼ºè°ƒå¿…é¡»è¿”å› (solution, cost) å…ƒç»„

---

## ğŸ“ åˆ›å»ºçš„æ–‡æ¡£

1. **`docs/current_issues.md`** - è¯¦ç»†é—®é¢˜è®°å½•
   - æ ¸å¿ƒé—®é¢˜åˆ†æ
   - é”™è¯¯å †æ ˆ
   - éœ€è¦ç ”ç©¶çš„é—®é¢˜åˆ—è¡¨

2. **`docs/research_findings.md`** - æ·±å…¥ç ”ç©¶æˆæœ
   - LLM é…ç½®æ­£ç¡®æµç¨‹
   - æ‰€æœ‰ç®—å­çš„ API æ±‡æ€»è¡¨
   - Workflow æ ‡å‡†æ¨¡æ¿
   - 6ç§æ¨èçš„å·¥ä½œæµæ¨¡å¼

3. **`docs/fix_summary.md`** (æœ¬æ–‡æ¡£) - ä¿®å¤æ€»ç»“

---

## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®

### ç«‹å³è¡ŒåŠ¨

**éœ€è¦é‡å¯è®­ç»ƒä»¥åº”ç”¨ä¿®å¤**ï¼š

```bash
# 1. åœæ­¢å½“å‰è®­ç»ƒ
kill 2203674

# 2. æ¸…ç©ºæ—¥å¿—
> logs/training_output.log

# 3. é‡æ–°å¯åŠ¨è®­ç»ƒ
CUDA_VISIBLE_DEVICES=2,3 PYTHONPATH=/home/yijia/.claude/11/AFlow:$PYTHONPATH \
  python3 train.py --config config/training.yaml > logs/training_output.log 2>&1 &

# 4. æŸ¥çœ‹æ–° PID
echo $!

# 5. ç›‘æ§æ—¥å¿—
tail -f logs/training_output.log
```

### é¢„æœŸæ”¹è¿›

åº”ç”¨ä¿®å¤åï¼Œé¢„æœŸçœ‹åˆ°ï¼š

1. âœ… **LLM é…ç½®é”™è¯¯æ¶ˆå¤±**
   - ä¸å†å‡ºç° `'dict' object has no attribute 'call_with_format'`
   - å¦‚æœå‡ºç°ç±»å‹ä¸åŒ¹é…ï¼Œä¼šè‡ªåŠ¨è½¬æ¢

2. âœ… **Qwen ç”Ÿæˆæ”¹å–„**
   - æ›´å¯èƒ½ç”Ÿæˆæ­£ç¡®çš„ Workflow æ ¼å¼
   - æ›´å¯èƒ½ä½¿ç”¨æ­£ç¡®çš„ç®—å­ API
   - ä½†ä¸ä¿è¯ 100% æ­£ç¡®ï¼ˆéœ€è¦è®­ç»ƒå­¦ä¹ ï¼‰

3. âœ… **æ›´å¥½çš„é”™è¯¯æ—¥å¿—**
   - å®Œæ•´çš„ traceback
   - è¯¦ç»†çš„ç±»å‹ä¿¡æ¯
   - æ›´å®¹æ˜“è°ƒè¯•

### è®­ç»ƒç›‘æ§è¦ç‚¹

é‡å¯è®­ç»ƒåï¼Œé‡ç‚¹å…³æ³¨ï¼š

1. **Step 1** æ˜¯å¦é¡ºåˆ©å®Œæˆï¼ˆæ—  AttributeErrorï¼‰
2. **DEBUG è¾“å‡º** æ˜¾ç¤º Qwen ç”Ÿæˆçš„æ˜¯å¦æ˜¯ `class Workflow:`
3. **æ˜¯å¦è¿˜æœ‰ AnswerGenerate instruction é”™è¯¯**
4. **Fallback ä½¿ç”¨ç‡** æ˜¯å¦é™ä½

---

## ğŸ“š å…³é”®å­¦ä¹ è¦ç‚¹

### AFlow æ ‡å‡†æ¨¡å¼

æ‰€æœ‰ Workflow å¿…é¡»éµå¾ªè¿™ä¸ªæ¨¡å¼ï¼š

```python
import workspace.{type}.workflows.template.operator as operator
from scripts.async_llm import create_llm_instance
from scripts.evaluator import DatasetType

class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)  # â† å…³é”®
        self.custom = operator.Custom(self.llm)      # â† ä¼ å…¥ AsyncLLM

    async def __call__(self, problem: str):
        solution = await self.custom(input=problem, instruction="")
        # â† å¿…é¡»è¿”å› (solution, cost) å…ƒç»„
        return solution['response'], self.llm.get_usage_summary()["total_cost"]
```

### ç®—å­ API é€ŸæŸ¥

| ç®—å­ | è°ƒç”¨ç­¾å |
|------|---------|
| Custom | `await self.custom(input=str, instruction=str)` |
| AnswerGenerate | `await self.answer_generate(input=str)` **NO instruction!** |
| Programmer | `await self.programmer(problem=str, analysis=str)` |
| ScEnsemble | `await self.sc_ensemble(solutions=List[str], problem=str)` |
| Review | `await self.review(problem=str, solution=str)` |
| Revise | `await self.revise(problem=str, solution=str, feedback=str)` |

### LLM é…ç½®æ­£ç¡®æµç¨‹

```python
# 1. åŠ è½½é…ç½®ç®¡ç†å™¨
from scripts.async_llm import LLMsConfig
llm_configs = LLMsConfig(models_dict)

# 2. è·å–ç‰¹å®šæ¨¡å‹é…ç½®ï¼ˆè¿”å› LLMConfig å®ä¾‹ï¼‰
llm_config = llm_configs.get("gpt-4o-mini")  # â† è¿”å› LLMConfigï¼Œä¸æ˜¯ dict

# 3. åˆ›å»º AsyncLLM
llm = create_llm_instance(llm_config)

# 4. ä¼ é€’ç»™ç®—å­
operator = Custom(llm)
```

---

## ğŸ”§ å¦‚æœä»æœ‰é—®é¢˜

### æ•…éšœæ’æŸ¥æ¸…å•

å¦‚æœé‡å¯åä»ç„¶å‡ºç°é”™è¯¯ï¼š

1. **æŸ¥çœ‹ DEBUG è¾“å‡º**
   ```bash
   grep "ğŸ” DEBUG: Qwen ç”Ÿæˆçš„åŸå§‹æ–‡æœ¬" logs/training_output.log | tail -3
   ```

2. **æ£€æŸ¥å®Œæ•´é”™è¯¯å †æ ˆ**
   ```bash
   grep -A 20 "Traceback" logs/training_output.log | tail -40
   ```

3. **éªŒè¯ç±»å‹è½¬æ¢**
   ```bash
   grep "âš ï¸  è­¦å‘Šï¼šget() è¿”å›äº† dict" logs/training_output.log
   ```

4. **æŸ¥çœ‹ Fallback ä½¿ç”¨ç‡**
   ```bash
   grep "ä½¿ç”¨fallbackå·¥ä½œæµ" logs/training_output.log | wc -l
   ```

### å¯èƒ½éœ€è¦çš„è¿›ä¸€æ­¥ä¿®å¤

å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯èƒ½éœ€è¦ï¼š

1. **æ·»åŠ è‡ªåŠ¨ä»£ç ä¿®å¤**ï¼ˆå¦‚ä¹‹å‰å»ºè®®çš„ `_parse_workflow_code` éªŒè¯ï¼‰
2. **æ·»åŠ  Few-shot ç¤ºä¾‹**åˆ° Prompt
3. **å®ç°å¥–åŠ±ä¿¡å·ä¿®æ­£**ï¼ˆæƒ©ç½šæ— æ•ˆç”Ÿæˆï¼‰
4. **é™ä½ temperature åˆ° 0.05**ï¼ˆæ›´ä¸¥æ ¼éµå¾ªæ¨¡æ¿ï¼‰

---

## âœ… æ€»ç»“

### å·²å®Œæˆ âœ…

1. âœ… æ·±å…¥ç ”ç©¶ AFlow ä»“åº“ï¼ˆ3ä¸ª agentsï¼Œ38+ æ–‡ä»¶ï¼‰
2. âœ… å‘ç°é—®é¢˜æ ¹æœ¬åŸå› ï¼ˆLLM é…ç½®ç±»å‹ã€ç®—å­ APIï¼‰
3. âœ… åº”ç”¨å…³é”®ä¿®å¤ï¼ˆç±»å‹æ£€æŸ¥ã€Prompt ä¼˜åŒ–ï¼‰
4. âœ… åˆ›å»ºè¯¦ç»†æ–‡æ¡£ï¼ˆé—®é¢˜è®°å½•ã€ç ”ç©¶æˆæœã€ä¿®å¤æ€»ç»“ï¼‰

### å¾…éªŒè¯ â¸ï¸

1. â¸ï¸ é‡å¯è®­ç»ƒéªŒè¯ä¿®å¤æ•ˆæœ
2. â¸ï¸ è§‚å¯Ÿ Qwen ç”Ÿæˆè´¨é‡æ˜¯å¦æ”¹å–„
3. â¸ï¸ ç›‘æ§é”™è¯¯ç‡æ˜¯å¦é™ä½

### å»ºè®®è¡ŒåŠ¨ â­ï¸

**ç«‹å³**ï¼šé‡å¯è®­ç»ƒï¼Œåº”ç”¨æ‰€æœ‰ä¿®å¤
**çŸ­æœŸ**ï¼šæ ¹æ®è®­ç»ƒæ•ˆæœè°ƒæ•´ temperature å’Œ prompt
**é•¿æœŸ**ï¼šè€ƒè™‘å®ç°å¥–åŠ±ä¿¡å·ä¿®æ­£å’Œ Curriculum Learning

---

**ä¿®å¤å®Œæˆæ—¶é—´**: 2025-11-16
**ä¸‹ä¸€æ­¥**: é‡å¯è®­ç»ƒå¹¶ç›‘æ§æ•ˆæœ ğŸš€
