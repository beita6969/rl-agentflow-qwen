#!/usr/bin/env python3
"""
æ£€æŸ¥è®­ç»ƒç¯å¢ƒ
"""
import sys
import os
import subprocess
from pathlib import Path

def check_environment():
    """å…¨é¢æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""

    print("=" * 70)
    print(" ğŸ” AFlow + ROLL è®­ç»ƒç¯å¢ƒæ£€æŸ¥")
    print("=" * 70)

    all_ok = True

    # 1. Pythonç‰ˆæœ¬
    print("\n[1/10] ğŸ Pythonç‰ˆæœ¬")
    python_version = sys.version_info
    if python_version >= (3, 8):
        print(f"  âœ… Python {python_version.major}.{python_version.minor}.{python_version.micro}")
    else:
        print(f"  âŒ Pythonç‰ˆæœ¬è¿‡ä½: {python_version}")
        all_ok = False

    # 2. PyTorch
    print("\n[2/10] ğŸ”¥ PyTorch")
    try:
        import torch
        print(f"  âœ… PyTorch {torch.__version__}")
        if torch.cuda.is_available():
            print(f"  âœ… CUDA {torch.version.cuda}")
            print(f"  âœ… å¯ç”¨GPU: {torch.cuda.device_count()}")
        else:
            print("  âŒ CUDAä¸å¯ç”¨")
            all_ok = False
    except ImportError:
        print("  âŒ PyTorchæœªå®‰è£…")
        all_ok = False

    # 3. Transformers
    print("\n[3/10] ğŸ¤— Transformers")
    try:
        import transformers
        print(f"  âœ… Transformers {transformers.__version__}")
    except ImportError:
        print("  âŒ Transformersæœªå®‰è£…")
        all_ok = False

    # 4. PEFT (LoRA)
    print("\n[4/10] ğŸ¯ PEFT")
    try:
        import peft
        print(f"  âœ… PEFT {peft.__version__}")
    except ImportError:
        print("  âŒ PEFTæœªå®‰è£…: pip install peft")
        all_ok = False

    # 5. GPU 2-3
    print("\n[5/10] ğŸ–¥ï¸  GPU 2-3")
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=index,name,memory.total', '--format=csv,noheader'],
            capture_output=True,
            text=True,
            check=True
        )
        gpus = result.stdout.strip().split('\n')
        gpu_2_ok = False
        gpu_3_ok = False
        for line in gpus:
            if line.startswith('2,'):
                print(f"  âœ… GPU 2: {line}")
                gpu_2_ok = True
            if line.startswith('3,'):
                print(f"  âœ… GPU 3: {line}")
                gpu_3_ok = True

        if not (gpu_2_ok and gpu_3_ok):
            print("  âŒ GPU 2æˆ–3ä¸å¯ç”¨")
            all_ok = False
    except Exception as e:
        print(f"  âŒ æ— æ³•æ£€æŸ¥GPU: {e}")
        all_ok = False

    # 6. ä»£ç†è¿›ç¨‹
    print("\n[6/10] ğŸ›¡ï¸  ä»£ç†è¿›ç¨‹ (PID 3819483)")
    try:
        os.kill(3819483, 0)
        print("  âœ… ä»£ç†è¿›ç¨‹æ­£åœ¨è¿è¡Œ")
    except OSError:
        print("  âš ï¸  ä»£ç†è¿›ç¨‹æœªæ‰¾åˆ°ï¼ˆå¯ä»¥ç»§ç»­ï¼Œä½†éœ€æ›´æ–°é…ç½®ï¼‰")

    # 7. AFlow
    print("\n[7/10] ğŸ“¦ AFlowæ¡†æ¶")
    aflow_path = Path('/home/yijia/.claude/11/AFlow')
    if aflow_path.exists():
        print(f"  âœ… AFlowè·¯å¾„å­˜åœ¨: {aflow_path}")
        if (aflow_path / 'scripts/operators.py').exists():
            print("  âœ… operators.pyå­˜åœ¨")
        else:
            print("  âŒ operators.pyä¸å­˜åœ¨")
            all_ok = False
    else:
        print("  âŒ AFlowè·¯å¾„ä¸å­˜åœ¨")
        all_ok = False

    # 8. ROLL
    print("\n[8/10] ğŸ“¦ ROLLæ¡†æ¶")
    roll_path = Path('/home/yijia/.claude/11/ROLL')
    if roll_path.exists():
        print(f"  âœ… ROLLè·¯å¾„å­˜åœ¨: {roll_path}")
    else:
        print("  âŒ ROLLè·¯å¾„ä¸å­˜åœ¨")
        all_ok = False

    # 9. é…ç½®æ–‡ä»¶
    print("\n[9/10] âš™ï¸  é…ç½®æ–‡ä»¶")
    config_files = [
        'config/training.yaml',
        'config/aflow_llm.yaml'
    ]
    for cf in config_files:
        if Path(cf).exists():
            print(f"  âœ… {cf}")
        else:
            print(f"  âŒ {cf} ä¸å­˜åœ¨")
            all_ok = False

    # 10. æ•°æ®é›†
    print("\n[10/10] ğŸ“‚ æ•°æ®é›†")
    dataset_files = [
        'data/train/mixed_dataset.jsonl',
        'data/val/mixed_dataset.jsonl'
    ]
    for df in dataset_files:
        if Path(df).exists():
            # ç»Ÿè®¡è¡Œæ•°
            with open(df) as f:
                lines = sum(1 for _ in f)
            print(f"  âœ… {df} ({lines} æ ·æœ¬)")
        else:
            print(f"  âŒ {df} ä¸å­˜åœ¨")
            all_ok = False

    # 11. Qwenæ¨¡å‹
    print("\n[11/10] ğŸ¤– Qwen2.5-7Bæ¨¡å‹")
    try:
        from transformers import AutoTokenizer
        tokenizer = AutoTokenizer.from_pretrained(
            "Qwen/Qwen2.5-7B-Instruct",
            trust_remote_code=True
        )
        print("  âœ… Qwen2.5-7B-Instructå·²ä¸‹è½½")
    except Exception as e:
        print(f"  âŒ Qwen2.5-7Bæ¨¡å‹æœªä¸‹è½½")
        print(f"     è¿è¡Œ: python3 scripts/download_model.py")
        all_ok = False

    # æ€»ç»“
    print("\n" + "=" * 70)
    if all_ok:
        print(" âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒ")
        print("=" * 70)
        print("\nğŸš€ å¯åŠ¨è®­ç»ƒ:")
        print("  python3 train.py")
        return 0
    else:
        print(" âŒ å­˜åœ¨é—®é¢˜ï¼Œè¯·å…ˆè§£å†³")
        print("=" * 70)
        return 1

if __name__ == "__main__":
    sys.exit(check_environment())
