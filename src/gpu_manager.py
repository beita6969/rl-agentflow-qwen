#!/usr/bin/env python
"""
GPU Manager - ç®¡ç†GPU 2-3çš„ä½¿ç”¨ï¼Œä¿æŠ¤ä»£ç†è¿›ç¨‹
"""
import os
import subprocess
import sys
from typing import List, Dict, Tuple
import time

class GPUManager:
    """GPUç®¡ç†å™¨ï¼šæ¸…ç†ã€ä¿æŠ¤ã€ç›‘æ§"""

    def __init__(
        self,
        target_gpus: List[int] = [2, 3],
        protected_pids: List[int] = [3819483],
        auto_clean: bool = True
    ):
        """
        Args:
            target_gpus: ç›®æ ‡GPUåˆ—è¡¨ï¼ˆä»…ä½¿ç”¨è¿™äº›GPUï¼‰
            protected_pids: å—ä¿æŠ¤çš„è¿›ç¨‹IDåˆ—è¡¨ï¼ˆä¸ä¼šè¢«æ¸…ç†ï¼‰
            auto_clean: æ˜¯å¦è‡ªåŠ¨æ¸…ç†ç›®æ ‡GPUä¸Šçš„å…¶ä»–è¿›ç¨‹
        """
        self.target_gpus = target_gpus
        self.protected_pids = protected_pids
        self.auto_clean = auto_clean

    def check_gpu_available(self) -> bool:
        """æ£€æŸ¥ç›®æ ‡GPUæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ['nvidia-smi', '--query-gpu=index,name,memory.total', '--format=csv,noheader'],
                capture_output=True,
                text=True,
                check=True
            )

            gpu_info = result.stdout.strip().split('\n')
            available_gpus = [int(line.split(',')[0]) for line in gpu_info]

            for gpu_id in self.target_gpus:
                if gpu_id not in available_gpus:
                    print(f"âŒ GPU {gpu_id} ä¸å¯ç”¨ï¼")
                    return False

            print(f"âœ… ç›®æ ‡GPU {self.target_gpus} å¯ç”¨")
            return True

        except Exception as e:
            print(f"âŒ æ£€æŸ¥GPUå¤±è´¥: {e}")
            return False

    def get_gpu_processes(self, gpu_id: int) -> List[Dict]:
        """è·å–æŒ‡å®šGPUä¸Šçš„æ‰€æœ‰è¿›ç¨‹"""
        try:
            result = subprocess.run(
                ['nvidia-smi', '--query-compute-apps=pid,process_name,used_memory', '--format=csv,noheader'],
                capture_output=True,
                text=True,
                check=True
            )

            # è·å–æ¯ä¸ªGPUçš„è¿›ç¨‹
            pmon_result = subprocess.run(
                ['nvidia-smi', 'pmon', '-c', '1'],
                capture_output=True,
                text=True
            )

            # è§£ænvidia-smiè¾“å‡º
            processes = []
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 3:
                        try:
                            pid = int(parts[0])
                            process_name = parts[1]
                            memory = parts[2]

                            # æ£€æŸ¥è¿›ç¨‹åœ¨å“ªä¸ªGPUä¸Š
                            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾nvidia-smiè¾“å‡ºæŒ‰GPUé¡ºåº
                            processes.append({
                                'pid': pid,
                                'name': process_name,
                                'memory': memory,
                                'gpu': gpu_id  # ç®€åŒ–ï¼šéœ€è¦æ›´ç²¾ç¡®çš„GPUåˆ†é…æ£€æµ‹
                            })
                        except ValueError:
                            continue

            return processes

        except Exception as e:
            print(f"âš ï¸  è·å–GPUè¿›ç¨‹å¤±è´¥: {e}")
            return []

    def get_all_target_gpu_processes(self) -> Dict[int, List[Dict]]:
        """è·å–æ‰€æœ‰ç›®æ ‡GPUä¸Šçš„è¿›ç¨‹"""
        try:
            # ä½¿ç”¨nvidia-smiæŸ¥è¯¢æ‰€æœ‰GPUè¿›ç¨‹
            result = subprocess.run(
                ['nvidia-smi', '--query-compute-apps=pid,gpu_uuid,process_name,used_memory',
                 '--format=csv,noheader'],
                capture_output=True,
                text=True,
                check=True
            )

            # è·å–GPU UUIDåˆ°IDçš„æ˜ å°„
            uuid_result = subprocess.run(
                ['nvidia-smi', '--query-gpu=index,uuid', '--format=csv,noheader'],
                capture_output=True,
                text=True,
                check=True
            )

            uuid_to_id = {}
            for line in uuid_result.stdout.strip().split('\n'):
                if line.strip():
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 2:
                        gpu_id = int(parts[0])
                        gpu_uuid = parts[1]
                        uuid_to_id[gpu_uuid] = gpu_id

            # æŒ‰GPUåˆ†ç»„è¿›ç¨‹
            gpu_processes = {gpu_id: [] for gpu_id in self.target_gpus}

            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 4:
                        try:
                            pid = int(parts[0])
                            gpu_uuid = parts[1]
                            process_name = parts[2]
                            memory = parts[3]

                            gpu_id = uuid_to_id.get(gpu_uuid)
                            if gpu_id in self.target_gpus:
                                gpu_processes[gpu_id].append({
                                    'pid': pid,
                                    'name': process_name,
                                    'memory': memory,
                                    'gpu': gpu_id
                                })
                        except ValueError:
                            continue

            return gpu_processes

        except subprocess.CalledProcessError as e:
            print(f"âš ï¸  nvidia-smiå‘½ä»¤å¤±è´¥: {e}")
            return {gpu_id: [] for gpu_id in self.target_gpus}
        except Exception as e:
            print(f"âš ï¸  è·å–GPUè¿›ç¨‹å¤±è´¥: {e}")
            return {gpu_id: [] for gpu_id in self.target_gpus}

    def check_protected_processes(self) -> bool:
        """æ£€æŸ¥å—ä¿æŠ¤çš„è¿›ç¨‹æ˜¯å¦å­˜åœ¨"""
        for pid in self.protected_pids:
            try:
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
                os.kill(pid, 0)  # ä¿¡å·0ä¸ä¼šæ€æ­»è¿›ç¨‹ï¼Œåªæ£€æŸ¥æ˜¯å¦å­˜åœ¨
                print(f"âœ… å—ä¿æŠ¤è¿›ç¨‹ {pid} æ­£åœ¨è¿è¡Œ")
            except OSError:
                print(f"âš ï¸  å—ä¿æŠ¤è¿›ç¨‹ {pid} æœªæ‰¾åˆ°ï¼ˆå¯èƒ½å·²åœæ­¢ï¼‰")
                return False

        return True

    def clean_target_gpus(self, force: bool = False) -> Tuple[int, int]:
        """
        æ¸…ç†ç›®æ ‡GPUä¸Šçš„è¿›ç¨‹ï¼ˆä¿æŠ¤å—ä¿æŠ¤è¿›ç¨‹ï¼‰

        Returns:
            (æˆåŠŸæ¸…ç†æ•°, å¤±è´¥æ•°)
        """
        if not self.auto_clean and not force:
            print("âš ï¸  è‡ªåŠ¨æ¸…ç†å·²ç¦ç”¨ï¼Œä½¿ç”¨force=Trueå¼ºåˆ¶æ¸…ç†")
            return 0, 0

        gpu_processes = self.get_all_target_gpu_processes()

        success_count = 0
        fail_count = 0

        for gpu_id, processes in gpu_processes.items():
            if not processes:
                print(f"âœ… GPU {gpu_id} æ— æ´»åŠ¨è¿›ç¨‹")
                continue

            print(f"\nğŸ” GPU {gpu_id} ä¸Šçš„è¿›ç¨‹:")
            for proc in processes:
                pid = proc['pid']
                name = proc['name']
                memory = proc['memory']

                # æ£€æŸ¥æ˜¯å¦ä¸ºå—ä¿æŠ¤è¿›ç¨‹
                if pid in self.protected_pids:
                    print(f"  ğŸ›¡ï¸  PID {pid} ({name}, {memory}) - å—ä¿æŠ¤ï¼Œè·³è¿‡")
                    continue

                print(f"  ğŸ¯ PID {pid} ({name}, {memory}) - å‡†å¤‡æ¸…ç†")

                try:
                    # å°è¯•ä¼˜é›…ç»ˆæ­¢
                    os.kill(pid, 15)  # SIGTERM
                    time.sleep(0.5)

                    # æ£€æŸ¥æ˜¯å¦å·²ç»ˆæ­¢
                    try:
                        os.kill(pid, 0)
                        # å¦‚æœè¿˜åœ¨è¿è¡Œï¼Œå¼ºåˆ¶æ€æ­»
                        print(f"    âš¡ å¼ºåˆ¶æ€æ­» PID {pid}")
                        os.kill(pid, 9)  # SIGKILL
                        time.sleep(0.2)
                    except OSError:
                        # è¿›ç¨‹å·²ç»ˆæ­¢
                        pass

                    print(f"    âœ… æˆåŠŸæ¸…ç† PID {pid}")
                    success_count += 1

                except PermissionError:
                    print(f"    âŒ æƒé™ä¸è¶³ï¼Œæ— æ³•æ¸…ç† PID {pid}")
                    fail_count += 1
                except ProcessLookupError:
                    print(f"    âœ… PID {pid} å·²ç»ä¸å­˜åœ¨")
                    success_count += 1
                except Exception as e:
                    print(f"    âŒ æ¸…ç† PID {pid} å¤±è´¥: {e}")
                    fail_count += 1

        print(f"\nğŸ“Š æ¸…ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
        return success_count, fail_count

    def setup_cuda_devices(self):
        """è®¾ç½®CUDAç¯å¢ƒå˜é‡ï¼Œä»…ä½¿ç”¨ç›®æ ‡GPU"""
        gpu_str = ','.join(map(str, self.target_gpus))
        os.environ['CUDA_VISIBLE_DEVICES'] = gpu_str
        print(f"âœ… è®¾ç½® CUDA_VISIBLE_DEVICES={gpu_str}")

    def verify_environment(self) -> bool:
        """éªŒè¯æ•´ä¸ªç¯å¢ƒé…ç½®"""
        print("=" * 60)
        print("ğŸ”§ éªŒè¯GPUç¯å¢ƒ")
        print("=" * 60)

        # 1. æ£€æŸ¥GPUå¯ç”¨æ€§
        if not self.check_gpu_available():
            return False

        # 2. æ£€æŸ¥å—ä¿æŠ¤è¿›ç¨‹
        self.check_protected_processes()

        # 3. è·å–å½“å‰GPUè¿›ç¨‹
        gpu_processes = self.get_all_target_gpu_processes()
        total_processes = sum(len(procs) for procs in gpu_processes.values())

        if total_processes > 0:
            print(f"\nâš ï¸  æ£€æµ‹åˆ° {total_processes} ä¸ªè¿›ç¨‹åœ¨ç›®æ ‡GPUä¸Šè¿è¡Œ")

            if self.auto_clean:
                print("ğŸ§¹ å¼€å§‹è‡ªåŠ¨æ¸…ç†...")
                success, fail = self.clean_target_gpus()

                if fail > 0:
                    print(f"âŒ æœ‰ {fail} ä¸ªè¿›ç¨‹æ¸…ç†å¤±è´¥")
                    return False
            else:
                print("âŒ è¯·æ‰‹åŠ¨æ¸…ç†GPUè¿›ç¨‹æˆ–å¯ç”¨auto_clean")
                return False

        # 4. è®¾ç½®CUDAç¯å¢ƒå˜é‡
        self.setup_cuda_devices()

        print("\n" + "=" * 60)
        print("âœ… GPUç¯å¢ƒéªŒè¯é€šè¿‡")
        print("=" * 60)

        return True

    def monitor_gpu_usage(self, interval: int = 5):
        """æŒç»­ç›‘æ§GPUä½¿ç”¨æƒ…å†µ"""
        try:
            while True:
                print(f"\n{'=' * 60}")
                print(f"â° GPUç›‘æ§ - {time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"{'=' * 60}")

                for gpu_id in self.target_gpus:
                    result = subprocess.run(
                        [
                            'nvidia-smi',
                            f'--id={gpu_id}',
                            '--query-gpu=index,name,temperature.gpu,utilization.gpu,memory.used,memory.total',
                            '--format=csv,noheader'
                        ],
                        capture_output=True,
                        text=True,
                        check=True
                    )

                    info = result.stdout.strip()
                    print(f"GPU {gpu_id}: {info}")

                time.sleep(interval)

        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç›‘æ§å·²åœæ­¢")


def main():
    """æµ‹è¯•GPUç®¡ç†å™¨"""
    import argparse

    parser = argparse.ArgumentParser(description="GPUç®¡ç†å™¨")
    parser.add_argument('--gpus', type=int, nargs='+', default=[2, 3], help='ç›®æ ‡GPUåˆ—è¡¨')
    parser.add_argument('--protected-pids', type=int, nargs='+', default=[3819483], help='å—ä¿æŠ¤çš„è¿›ç¨‹ID')
    parser.add_argument('--no-auto-clean', action='store_true', help='ç¦ç”¨è‡ªåŠ¨æ¸…ç†')
    parser.add_argument('--monitor', action='store_true', help='æŒç»­ç›‘æ§GPU')
    parser.add_argument('--force-clean', action='store_true', help='å¼ºåˆ¶æ¸…ç†GPU')

    args = parser.parse_args()

    manager = GPUManager(
        target_gpus=args.gpus,
        protected_pids=args.protected_pids,
        auto_clean=not args.no_auto_clean
    )

    if args.force_clean:
        manager.clean_target_gpus(force=True)
    elif args.monitor:
        if manager.verify_environment():
            manager.monitor_gpu_usage()
    else:
        manager.verify_environment()


if __name__ == "__main__":
    main()
